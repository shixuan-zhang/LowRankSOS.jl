include("./toric.jl")

# use packages for experiments and result collection
using Statistics, DataFrames, CSV

# function that builds the coordinate ring of a Veronese variety
function build_ring_Veronese(
        dim::Int,
        deg::Int
    )
    # define the lattice polytope vertex matrix
    mat_vertices = vcat(diagm(ones(Int,dim).*deg),zeros(Int,dim)')
    # get the coordinate ring information
    coord_ring = build_ring_from_polytope(mat_vertices)
    return coord_ring
end

# function that conducts experiments of the low-rank SOS method on the Veronese variety
function experiment_Veronese(
        deg::Int,
        dim::Int,
        mult_num_sq::Vector{Float64} = Float64[];
        num_rep::Int = 1,
        REL_MAX_ITER::Int = 100
    )
    # define the lattice polytope vertex matrix
    mat_vertices = vcat(diagm(ones(Int,dim).*deg),zeros(Int,dim)')
    # get the coordinate ring information
    coord_ring = build_ring_from_polytope(mat_vertices)
    # set the number of squares (that satisfies the Barvinok-Pataki bound)
    num_BP_bound = ceil(Int, sqrt(2*(binomial(2*deg+dim,2*deg)-1)))
    if length(mult_num_sq) == 0
        mult_num_sq = [1.0]
    end
    # print the experiment setup information
    println("Start experiments on Veronese variety with degree = ", deg, ", and dimension = ", dim, "\n\n")
    # run a single test
    if num_rep == 1
        # choose randomly a target (generated by a random tuple of linear forms with full rank)
        tuple_random = rand(coord_ring.dim1*coord_ring.dim1)
        target_sos = get_sos(tuple_random, coord_ring)
        for mult in mult_num_sq
            num_square = ceil(Int,mult*num_BP_bound)
            println("Run different local optimization methods with ", num_square, " squares...")
            # choose randomly a starting point
            tuple_start = rand(num_square*coord_ring.dim1)
            # run the line search method
            solve_gradient_descent(num_square, target_sos, coord_ring, tuple_linear_forms=tuple_start, print_level=1)
            solve_BFGS_descent(num_square, target_sos, coord_ring, tuple_linear_forms=tuple_start, print_level=1)
            solve_lBFGS_descent(num_square, target_sos, coord_ring, tuple_linear_forms=tuple_start, print_level=1)
            solve_CG_descent(num_square, target_sos, coord_ring, tuple_linear_forms=tuple_start, print_level=1, str_CG_update="PolakRibiere")
            solve_CG_descent(num_square, target_sos, coord_ring, tuple_linear_forms=tuple_start, print_level=1, str_CG_update="HagerZhang")
            solve_CG_push_descent(num_square, target_sos, coord_ring, tuple_linear_forms=tuple_start, print_level=1)
            solve_CG_push_descent(num_square, target_sos, coord_ring, 1, tuple_linear_forms=tuple_start, print_level=1)
            solve_CG_push_descent(num_square, target_sos, coord_ring, 0, tuple_linear_forms=tuple_start, print_level=1)
            # run the direct path algorithm
            move_direct_path(num_square, target_sos, coord_ring, tuple_linear_forms=tuple_start, print_level=1, str_descent_method="CG")
            move_direct_path(num_square, target_sos, coord_ring, tuple_linear_forms=tuple_start, print_level=1, str_descent_method="lBFGS")
            # call the external solver for comparison
            call_NLopt(num_square, target_sos, coord_ring, tuple_linear_forms=tuple_start, print_level=1)
        end
    # run a batch of multiple tests
    elseif num_rep > 1
        # check the dimension of the linear forms
        dim_linear = binomial(deg+dim,deg)
        # record whether each experiment run achieves global minimum 0
        result_success = Dict{Float64,Vector{Int}}()
        result_seconds = Dict{Float64,Vector{Float64}}()
        result_residue = Dict{Float64,Vector{Float64}}()
        for mult in mult_num_sq
            result_success[mult] = zeros(Int,num_rep)
            result_seconds[mult] = zeros(num_rep)
            result_residue[mult] = zeros(num_rep)
        end
        for idx in 1:num_rep
            println("\n" * "="^80)
            # choose randomly a target
            tuple_random = rand(coord_ring.dim1*coord_ring.dim1)
            target_sos = get_sos(tuple_random, coord_ring)
            # choose randomly a starting point
            tuple_BP_start = rand(num_BP_bound*coord_ring.dim1)
            # loop over different numbers of squares
            for mult in mult_num_sq
                # avoid using numbers of squares larger than the dimension of linear forms
                num_square = min(ceil(Int,mult*num_BP_bound),coord_ring.dim1)
                println("Use ", num_square, " squares for the local optimization method...")
                # embed the starting tuple of linear forms
                tuple_start = embed_tuple(tuple_BP_start, num_BP_bound, num_square, random=true)
                # solve the problem and record the time
                time_start = time()
                vec_sol, val_res, flag_conv = call_NLopt(num_square, target_sos, coord_ring, tuple_linear_forms=tuple_start, num_max_eval=coord_ring.dim1*REL_MAX_ITER, print_level=1)
                time_end = time()
                # check the optimal value
                if val_res < LowRankSOS.VAL_TOL * max(1.0, norm(target_sos))
                    result_success[mult][idx] = 1
                    result_seconds[mult][idx] = time_end-time_start
                else
                    result_seconds[mult][idx] = NaN
                    if flag_conv
                        result_success[mult][idx] = -1
                        result_residue[mult][idx] = val_res / max(1.0, norm(target_sos))
                        # check the optimality conditions
                        vec_sos = get_sos(vec_sol, coord_ring)
                        mat_Jac = build_Jac_mat(vec_sol, coord_ring)
                        vec_grad = 2*mat_Jac'*(vec_sos-target_sos)
                        mat_Hess = build_Hess_mat(num_square, vec_sol, target_sos, coord_ring)
                        printfmtln("Local min encountered with grad norm = {:<10.4e} and the min Hessian eigenval = {:<10.4e}",
                                   norm(vec_grad), minimum(eigen(mat_Hess).values))
                        # start the adaptive moves along a direct path connecting the quadrics
                        println("Re-solve the problem using the direct path method...")
                        vec_sol, val_res = move_direct_path(num_square, target_sos, coord_ring, tuple_linear_forms=tuple_start, str_descent_method="lBFGS-NLopt", print_level=1, val_threshold=LowRankSOS.VAL_TOL*max(1.0,norm(target_sos)))
                        vec_sos = get_sos(vec_sol, coord_ring)
                        if norm(vec_sos-target_sos) < LowRankSOS.VAL_TOL*max(1.0,norm(target_sos))
                            result_success[mult][idx] = 2
                            result_residue[mult][idx] = 0.0
                        end
                    end
                end
            end
        end
        for mult in mult_num_sq
            println("\nResult summary for ", mult*num_BP_bound, " squares:")
            println("Global optima are found in ", count(x->x>0, result_success[mult]), " out of ", num_rep, " experiment runs.")
            println("Direct-path method is used in ", count(x->x>1, result_success[mult]), " experiment runs.")
            println("The average wall clock time for test runs is ", mean(filter(!isnan, result_seconds[mult])), " seconds.")
        end
        # return the arrays of successful runs and the average time for batch experiments
        SUCC = [count(x->x>0, result_success[mult]) for mult in mult_num_sq]
        FAIL = [count(x->x<0, result_success[mult]) for mult in mult_num_sq]
        TIME = [mean(filter(!isnan, result_seconds[mult])) for mult in mult_num_sq]
        DIST = [maximum(result_residue[mult]) for mult in mult_num_sq]
        return SUCC, FAIL, TIME, DIST
    end
end

function batch_experiment_Veronese(
        set_deg_dim::Vector{Tuple{Int,Int}},
        set_mult::Vector{Float64} = [1.0,2.0];
        str_file::String = "result_Veronese",
        num_rep::Int = 1000
    )
    num_test = length(set_deg_dim)
    num_mult = length(set_mult)
    # prepare the output columns
    NAME = String[]
    MULT = Float64[]
    SUCC = Int[]
    FAIL = Int[]
    TIME = Float64[]
    DIST = Float64[]
    # start the main tests
    for idx_test in 1:num_test
        # create the name tag from the heights
        append!(NAME, [join(set_deg_dim[idx_test], "-") for _ in 1:num_mult])
        append!(MULT, set_mult)
        # get the degree and dimension
        deg = set_deg_dim[idx_test][1]
        dim = set_deg_dim[idx_test][2]
        # execute the experiment
        succ, fail, time, dist = experiment_Veronese(deg,dim,set_mult,num_rep=num_rep)
        append!(SUCC, succ)
        append!(FAIL, fail)
        append!(TIME, time)
        append!(DIST, dist)
        # write to the output file
        result = DataFrame(:NAME => NAME, :MULT => MULT, :SUCC => SUCC, :TIME => TIME, :FAIL => FAIL, :DIST => DIST)
        CSV.write(str_file*".csv", result)
        println("\n\n\n")
    end
end

